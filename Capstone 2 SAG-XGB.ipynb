{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Short Answer Grading\n",
    "\n",
    "## ShortAnswerGrading V2 Data and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data/sag2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'sagemaker/short_answer'\n",
    "\n",
    "# upload all data to S3\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train_xgb.csv'), key_prefix=prefix)\n",
    "validation_location = sagemaker_session.upload_data(os.path.join(data_dir, 'validate_xgb.csv'), key_prefix=prefix)\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=validation_location, content_type='csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(data_dir, \"answers.csv\"))\n",
    "train_data = pd.read_csv(os.path.join(data_dir, \"train_xgb.csv\"), header=None, names=None)\n",
    "validate_data = pd.read_csv(os.path.join(data_dir, \"validate_xgb.csv\"), header=None, names=None)\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "vocab = pd.read_csv(os.path.join(data_dir, \"vocab.csv\"), header=None, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "509\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2442 entries, 0 to 2441\n",
      "Data columns (total 4 columns):\n",
      "id         2442 non-null float64\n",
      "answer     2442 non-null object\n",
      "score      2442 non-null float64\n",
      "correct    2442 non-null float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 76.4+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1963"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['answer_length'] = raw_data['answer'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.hist(raw_data['answer_length'].values, bins=20)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "plt.xticks(np.arange(0, 1000, step=50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(raw_data['correct'],bins=2)\n",
    "plt.xticks(np.arange(2), ['False', 'True'])\n",
    "plt.rcParams[\"figure.figsize\"] = [2,2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_data[0],bins=2)\n",
    "plt.xticks(np.arange(2), ['False', 'True'])\n",
    "plt.rcParams[\"figure.figsize\"] = [2,2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(validate_data[0],bins=2)\n",
    "plt.xticks(np.arange(2), ['False', 'True'])\n",
    "plt.rcParams[\"figure.figsize\"] = [2,2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ4AAACPCAYAAAALD2JFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAB8BJREFUeJzt3W+sFFcdxvHvU2wjqcaWQrEB4lrFKjYW6w1pxBcarCltYmtiEKJIjCk1oYkaX4jVaF/Wxj+RqI1YiTRp658IqbFEi8REjdpyIZUClZQSmkIQaK3aYo3h9ueLOfdmuOzl/tnZ+yu7zyfZ3JmzM7PnZp/MmdmZOUcRgdl0uyC7AtafHDxL4eBZCgfPUjh4lsLBsxQOnqVw8CyFg2cpXpNdAYDZs2dHq9XKroZN0a5du56LiDmTWedVEbxWq8Xg4GB2NWyKJD0z2XXc1FoKB89SOHiW4lVxjNfrWusfzq5CYw7fdVMj2xl3jydpk6QTkvbWymZJ2i7pqfL30lIuSRskHZS0R9K1jdTSes5EmtofAzeMKlsP7IiIhcCOMg+wHFhYXmuBe5qppvWacYMXEb8H/jGq+GZgc5neDNxSK78vKn8BLpF0RVOVtd4x1ZOLuRFxrEz/HZhbpucBz9aWO1LKziJpraRBSYMnT56cYjXsfNXxWW1UD21M+sGNiNgYEQMRMTBnzqR+9LYeMNXgHR9uQsvfE6X8KLCgttz8UmZ2hqkG75fAmjK9BnioVv7JcnZ7HfCvWpNsNmLc3/EkPQi8H5gt6QjwNeAu4GeSPg08A6woi28DbgQOAv8BPtWFOlsPGDd4EbFqjLeWtVk2gHWdVsp6ny+ZWQoHz1I4eJbCwbMUDp6lcPAshYNnKRw8S+HgWQoHz1I4eJbCwbMUDp6lcPAshYNnKRw8SzHlngQkXQX8tFZ0JfBV4BLgVmD40bE7ImLblGtoPWnKwYuIA8BiAEkzqB7q2Up1u/u3I+IbjdTQelJTTe0y4OmImHQ/adafmgreSuDB2vztpe+UTcP9qozmB7r7W8fBk3QR8GHg56XoHuAtVM3wMeCb7dbzA939rYk93nJgd0QcB4iI4xExFBGvAD8EljTwGdZjmgjeKmrN7KhOej4C7D1rDet7HXXMKOli4Hrgtlrx3ZIWU/WncnjUe2ZAh8GLiFPAZaPKVndUI+sLvnJhKRw8S+HgWQoHz1I4eJbCwbMUDp6lcPAshYNnKRw8S+HgWQoHz1I4eJbCwbMUDp6lcPAsRad3IB8GXgSGgNMRMSBpFtWD3i2qO5BXRMQLnVXTek0Te7wPRMTiiBgo82ON3m02ohtN7Vijd5uN6DR4ATwiaZektaVsrNG7z+AHuvtbR8d4wPsi4qiky4Htkv5WfzMiQlLb0bsjYiOwEWBgYGDSI3zb+a2jPV5EHC1/T1B12LOEsUfvNhsx5eBJuljS64engQ9RPbw91ujdZiM6aWrnAlslDW/ngYj4taSdtB+922xEJ/3jHQKuaVP+PG1G7zar85ULS9HpWW3XtNY/nF0F6yLv8SyFg2cpHDxL4eBZCgfPUjh4lsLBsxQOnqVw8CyFg2cpHDxL4eBZCgfPUjh4lqKTW98XSPqdpP2S9kn6bCm/U9JRSY+X143NVdd6RSf3450GvhARu8uzF7skbS/veYRuO6dObn0/RjUeLRHxoqQngXlNVcx6WyPHeJJawLuBR0uRR+i2c2pihO7XAb8APhcR/8YjdNsEdBQ8SRdShe7+iNgCHqHbJqaTs1oBPwKejIhv1co9QreNq5Oz2qXAauAJSY+XsjuAVR6h28bTyVntHwG1eWvb1Ktj/cJXLiyFg2cpHDxL4eBZCgfPUjh4lsLBsxQOnqVw8CyFg2cpHDxL4eBZCgfPUjh4lsLBsxRdCZ6kGyQdkHRQksertbM0HjxJM4DvAcuBRVR3JC9q+nPs/NaNPd4S4GBEHIqI/wE/oRo82WxEN4I3D3i2Nn8EP+hto6QNKVVG9B4e1fslSQdGLTIbeG56a2Xj0dfbfi9vmux2uhG8o8CC2vz8UnaG+gjd7UgajIiB5qtnnWjqe+lGU7sTWCjpzZIuAlZSDZ5sNqLxPV5EnJZ0O/AbYAawKSL2Nf05dn7ryjFeRGyj8+drx2yGLVUj34sioontmE2KL5lZimn7OUXSEPBEreiWiDg8xrIt4FcRcXX3a9bfJF0G7CizbwSGgOEOC5eUiwCNm87f8V6OiMXT+Hk2ARHxPFVfhki6E3hpdDfCpWcwla7nGpHa1EpqSfqDpN3l9d42y7xT0mOlI+89khaW8k/Uyn9QrhFbQyS9tXSsfj+wD1gg6Z+191dKurdMz5W0pfTw+pik68bb/nQGb2atJ/itpewEcH1EXAt8DNjQZr3PAN8pe8sB4Iikd5Tll5byIeDj3f8X+s7bqTpSX0SbiwA1G4C7yw/LK4B7x9twdlN7IfDd0p/eEPC2Nuv9GfiypPnAloh4StIy4D3AzqoVYCZViK1ZT0fE4ASW+yBwVfkuAC6VNDMiXh5rhbRrtcXngePANVR73/+OXiAiHpD0KHATsE3SbVT98m2OiC9NZ2X70Kna9Cuc2R/ia2vTYpInItk/p7wBOFYOWldTXek4g6QrgUMRsQF4CHgX1VnYRyVdXpaZJWnSF6pt4sp39IKkhZIuoOpmeNhvgXXDM6UFO6fs4H0fWCPpr1THE6faLLMC2Fu6u70auC8i9gNfAR6RtAfYDlzRZl1r1hepLoX+iep2t2HrgKXl5G8/cOt4G/KVC0uRvcezPuXgWQoHz1I4eJbCwbMUDp6lcPAshYNnKf4PQN06GUTQTuIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_data[0],bins=2)\n",
    "plt.xticks(np.arange(2), ['False', 'True'])\n",
    "plt.rcParams[\"figure.figsize\"] = [2,2]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to retrieve the location of the container which is provided by Amazon for using XGBoost.\n",
    "# As a matter of convenience, the training and inference code both use the same container.\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "\n",
    "estimator.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silence=1,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=50,\n",
    "                        num_round=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-02 13:50:30 Starting - Starting the training job...\n",
      "2019-07-02 13:50:31 Starting - Launching requested ML instances......\n",
      "2019-07-02 13:51:34 Starting - Preparing the instances for training......\n",
      "2019-07-02 13:52:42 Downloading - Downloading input data...\n",
      "2019-07-02 13:53:16 Training - Downloading the training image..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-07-02:13:53:37:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-07-02:13:53:37:INFO] File size need to be processed in the node: 1.23mb. Available memory size in the node: 8470.11mb\u001b[0m\n",
      "\u001b[31m[2019-07-02:13:53:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[13:53:37] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[13:53:37] 1200x176 matrix with 211200 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-07-02:13:53:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[13:53:37] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[13:53:37] 509x176 matrix with 89584 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[0]#011train-error:0.269167#011validation-error:0.318271\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-error hasn't improved in 50 rounds.\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[1]#011train-error:0.246667#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[2]#011train-error:0.2375#011validation-error:0.286837\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[3]#011train-error:0.24#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[4]#011train-error:0.250833#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[5]#011train-error:0.234167#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[6]#011train-error:0.228333#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[7]#011train-error:0.2325#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[8]#011train-error:0.230833#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[9]#011train-error:0.231667#011validation-error:0.273084\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[10]#011train-error:0.221667#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[11]#011train-error:0.2175#011validation-error:0.277014\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[12]#011train-error:0.211667#011validation-error:0.277014\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[13]#011train-error:0.209167#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[14]#011train-error:0.204167#011validation-error:0.277014\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[15]#011train-error:0.198333#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[16]#011train-error:0.195833#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[17]#011train-error:0.191667#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[18]#011train-error:0.188333#011validation-error:0.273084\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[19]#011train-error:0.185833#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[20]#011train-error:0.186667#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[21]#011train-error:0.180833#011validation-error:0.273084\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[22]#011train-error:0.181667#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[23]#011train-error:0.184167#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[24]#011train-error:0.178333#011validation-error:0.275049\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[25]#011train-error:0.176667#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[26]#011train-error:0.171667#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[27]#011train-error:0.171667#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[28]#011train-error:0.165833#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[29]#011train-error:0.1625#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[30]#011train-error:0.160833#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[31]#011train-error:0.151667#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[32]#011train-error:0.153333#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[33]#011train-error:0.1475#011validation-error:0.273084\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[34]#011train-error:0.148333#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[35]#011train-error:0.149167#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[36]#011train-error:0.150833#011validation-error:0.27112\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[37]#011train-error:0.146667#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[38]#011train-error:0.139167#011validation-error:0.277014\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[39]#011train-error:0.138333#011validation-error:0.277014\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[40]#011train-error:0.135833#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[41]#011train-error:0.136667#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[42]#011train-error:0.136667#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[43]#011train-error:0.136667#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 18 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[44]#011train-error:0.1325#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[45]#011train-error:0.135833#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[46]#011train-error:0.1375#011validation-error:0.278978\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[47]#011train-error:0.134167#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[48]#011train-error:0.1325#011validation-error:0.288802\u001b[0m\n",
      "\u001b[31m[13:53:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[49]#011train-error:0.1325#011validation-error:0.288802\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 20 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[50]#011train-error:0.130833#011validation-error:0.288802\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[51]#011train-error:0.130833#011validation-error:0.288802\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[52]#011train-error:0.128333#011validation-error:0.292731\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[53]#011train-error:0.125#011validation-error:0.286837\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[54]#011train-error:0.125#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[55]#011train-error:0.126667#011validation-error:0.282908\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[56]#011train-error:0.126667#011validation-error:0.286837\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[57]#011train-error:0.124167#011validation-error:0.286837\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[58]#011train-error:0.125#011validation-error:0.286837\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[59]#011train-error:0.12#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[60]#011train-error:0.12#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[61]#011train-error:0.120833#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[62]#011train-error:0.121667#011validation-error:0.284872\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[63]#011train-error:0.12#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[64]#011train-error:0.119167#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[65]#011train-error:0.115#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31m[13:53:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[66]#011train-error:0.1175#011validation-error:0.280943\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[16]#011train-error:0.195833#011validation-error:0.27112\n",
      "\u001b[0m\n",
      "\n",
      "2019-07-02 13:53:49 Uploading - Uploading generated training model\n",
      "2019-07-02 13:53:49 Completed - Training job completed\n",
      "Billable seconds: 68\n",
      "CPU times: user 423 ms, sys: 38.7 ms, total: 461 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train estimator on S3 training data\n",
    "estimator.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost-2019-07-02-13-50-30-261'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure to import the relevant objects used to construct the tuner\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = estimator, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 18, # The total number of models to train\n",
    "                                               max_parallel_jobs = 6, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost-190702-1956-017-2473c488\n"
     ]
    }
   ],
   "source": [
    "training_job_name = xgb_hyperparameter_tuner.best_training_job()\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-02 20:06:49 Starting - Preparing the instances for training\n",
      "2019-07-02 20:06:49 Downloading - Downloading input data\n",
      "2019-07-02 20:06:49 Training - Training image download completed. Training in progress.\n",
      "2019-07-02 20:06:49 Uploading - Uploading generated training model\n",
      "2019-07-02 20:06:49 Completed - Training job completed\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-07-02:20:06:38:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-07-02:20:06:38:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[31m[2019-07-02:20:06:38:INFO] File size need to be processed in the node: 1.23mb. Available memory size in the node: 8459.77mb\u001b[0m\n",
      "\u001b[31m[2019-07-02:20:06:38:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[20:06:38] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[20:06:38] 1200x176 matrix with 211200 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-07-02:20:06:38:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[20:06:38] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[20:06:38] 509x176 matrix with 89584 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[0]#011train-rmse:0.488701#011validation-rmse:0.494312\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-rmse hasn't improved in 50 rounds.\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[1]#011train-rmse:0.477462#011validation-rmse:0.488799\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[2]#011train-rmse:0.468988#011validation-rmse:0.483789\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[3]#011train-rmse:0.459497#011validation-rmse:0.478721\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[4]#011train-rmse:0.451035#011validation-rmse:0.474598\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 30 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[5]#011train-rmse:0.44303#011validation-rmse:0.470733\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 42 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[6]#011train-rmse:0.434767#011validation-rmse:0.466663\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[7]#011train-rmse:0.42616#011validation-rmse:0.463107\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[8]#011train-rmse:0.41848#011validation-rmse:0.460434\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[9]#011train-rmse:0.411833#011validation-rmse:0.45761\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 40 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[10]#011train-rmse:0.404772#011validation-rmse:0.454938\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[11]#011train-rmse:0.398383#011validation-rmse:0.452447\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[12]#011train-rmse:0.392465#011validation-rmse:0.450632\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 52 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[13]#011train-rmse:0.387734#011validation-rmse:0.449095\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[14]#011train-rmse:0.382665#011validation-rmse:0.447431\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 34 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[15]#011train-rmse:0.378579#011validation-rmse:0.44607\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 32 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[16]#011train-rmse:0.374816#011validation-rmse:0.445174\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 44 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[17]#011train-rmse:0.369723#011validation-rmse:0.444047\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 38 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[18]#011train-rmse:0.364862#011validation-rmse:0.443113\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 34 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[19]#011train-rmse:0.360599#011validation-rmse:0.442392\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 56 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[20]#011train-rmse:0.356582#011validation-rmse:0.441247\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 44 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[21]#011train-rmse:0.353554#011validation-rmse:0.440489\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 30 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[22]#011train-rmse:0.350749#011validation-rmse:0.439914\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 56 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[23]#011train-rmse:0.347313#011validation-rmse:0.439415\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 58 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[24]#011train-rmse:0.343721#011validation-rmse:0.43868\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 56 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[25]#011train-rmse:0.340863#011validation-rmse:0.437829\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[26]#011train-rmse:0.338984#011validation-rmse:0.437501\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 46 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[27]#011train-rmse:0.335994#011validation-rmse:0.437074\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[28]#011train-rmse:0.333491#011validation-rmse:0.437278\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 36 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[29]#011train-rmse:0.330814#011validation-rmse:0.436947\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 50 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[30]#011train-rmse:0.327472#011validation-rmse:0.436735\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[31]#011train-rmse:0.324894#011validation-rmse:0.436755\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 60 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[32]#011train-rmse:0.322163#011validation-rmse:0.436829\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 38 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[33]#011train-rmse:0.319423#011validation-rmse:0.436817\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 68 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[34]#011train-rmse:0.317362#011validation-rmse:0.436722\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 38 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[35]#011train-rmse:0.315413#011validation-rmse:0.436484\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[36]#011train-rmse:0.314531#011validation-rmse:0.436136\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[37]#011train-rmse:0.313247#011validation-rmse:0.436149\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[38]#011train-rmse:0.310962#011validation-rmse:0.435917\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 72 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[39]#011train-rmse:0.309476#011validation-rmse:0.435597\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[40]#011train-rmse:0.307839#011validation-rmse:0.435456\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 48 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[41]#011train-rmse:0.306201#011validation-rmse:0.435274\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[42]#011train-rmse:0.304351#011validation-rmse:0.435081\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[43]#011train-rmse:0.303573#011validation-rmse:0.435096\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 54 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[44]#011train-rmse:0.302021#011validation-rmse:0.435298\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 30 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[45]#011train-rmse:0.301222#011validation-rmse:0.435429\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 34 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[46]#011train-rmse:0.300223#011validation-rmse:0.435508\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 54 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[47]#011train-rmse:0.298825#011validation-rmse:0.435512\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 44 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[48]#011train-rmse:0.297864#011validation-rmse:0.435693\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[49]#011train-rmse:0.296508#011validation-rmse:0.435741\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 44 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[50]#011train-rmse:0.294705#011validation-rmse:0.435765\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 34 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[51]#011train-rmse:0.293823#011validation-rmse:0.435445\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 54 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[52]#011train-rmse:0.292099#011validation-rmse:0.435175\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 44 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[53]#011train-rmse:0.291221#011validation-rmse:0.435667\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[54]#011train-rmse:0.290257#011validation-rmse:0.435606\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 52 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[55]#011train-rmse:0.28888#011validation-rmse:0.435602\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[56]#011train-rmse:0.288027#011validation-rmse:0.435896\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[57]#011train-rmse:0.287444#011validation-rmse:0.43582\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[31m[58]#011train-rmse:0.287248#011validation-rmse:0.43603\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 34 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[59]#011train-rmse:0.286161#011validation-rmse:0.436389\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 54 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[60]#011train-rmse:0.284547#011validation-rmse:0.436559\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 54 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[61]#011train-rmse:0.283211#011validation-rmse:0.43622\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 24 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[62]#011train-rmse:0.282739#011validation-rmse:0.436454\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 42 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[63]#011train-rmse:0.280888#011validation-rmse:0.436177\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 58 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[64]#011train-rmse:0.279243#011validation-rmse:0.435792\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 52 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[65]#011train-rmse:0.278191#011validation-rmse:0.435671\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 30 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[66]#011train-rmse:0.277638#011validation-rmse:0.435708\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 36 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[67]#011train-rmse:0.276082#011validation-rmse:0.435858\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 76 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[68]#011train-rmse:0.275339#011validation-rmse:0.435846\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 48 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[69]#011train-rmse:0.27403#011validation-rmse:0.435584\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 26 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[70]#011train-rmse:0.273346#011validation-rmse:0.43571\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 40 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[71]#011train-rmse:0.272019#011validation-rmse:0.435593\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[72]#011train-rmse:0.271422#011validation-rmse:0.435681\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 54 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[73]#011train-rmse:0.270597#011validation-rmse:0.435298\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 78 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[74]#011train-rmse:0.269897#011validation-rmse:0.434865\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[75]#011train-rmse:0.269215#011validation-rmse:0.434991\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 48 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[76]#011train-rmse:0.268388#011validation-rmse:0.434968\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[77]#011train-rmse:0.267759#011validation-rmse:0.434963\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 54 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[78]#011train-rmse:0.266917#011validation-rmse:0.434986\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 44 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[79]#011train-rmse:0.265948#011validation-rmse:0.434953\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[80]#011train-rmse:0.264943#011validation-rmse:0.435212\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 80 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[81]#011train-rmse:0.26415#011validation-rmse:0.435112\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 48 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[82]#011train-rmse:0.263846#011validation-rmse:0.435168\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 40 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[83]#011train-rmse:0.26328#011validation-rmse:0.435305\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 54 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[84]#011train-rmse:0.262593#011validation-rmse:0.435492\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 56 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[85]#011train-rmse:0.261828#011validation-rmse:0.435278\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 82 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[86]#011train-rmse:0.261185#011validation-rmse:0.435403\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 82 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[31m[87]#011train-rmse:0.260531#011validation-rmse:0.435355\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 78 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[88]#011train-rmse:0.260517#011validation-rmse:0.435349\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 52 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[89]#011train-rmse:0.25957#011validation-rmse:0.435133\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[90]#011train-rmse:0.259543#011validation-rmse:0.435122\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[91]#011train-rmse:0.2578#011validation-rmse:0.435152\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 68 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[92]#011train-rmse:0.25699#011validation-rmse:0.435285\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 76 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[93]#011train-rmse:0.256206#011validation-rmse:0.435143\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 64 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[94]#011train-rmse:0.255458#011validation-rmse:0.435084\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 80 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[95]#011train-rmse:0.255242#011validation-rmse:0.435193\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[96]#011train-rmse:0.255224#011validation-rmse:0.435185\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 54 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[97]#011train-rmse:0.255011#011validation-rmse:0.434868\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 44 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[98]#011train-rmse:0.254061#011validation-rmse:0.435228\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 50 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[99]#011train-rmse:0.253803#011validation-rmse:0.4353\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 72 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[100]#011train-rmse:0.253759#011validation-rmse:0.435283\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 66 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[101]#011train-rmse:0.253265#011validation-rmse:0.435315\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[102]#011train-rmse:0.253209#011validation-rmse:0.435293\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 60 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[103]#011train-rmse:0.252845#011validation-rmse:0.435452\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 60 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[104]#011train-rmse:0.25234#011validation-rmse:0.435949\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 42 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[31m[105]#011train-rmse:0.251592#011validation-rmse:0.435956\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[106]#011train-rmse:0.250562#011validation-rmse:0.435938\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 28 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[107]#011train-rmse:0.250041#011validation-rmse:0.436025\u001b[0m\n",
      "\u001b[31m[20:06:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 56 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[108]#011train-rmse:0.24933#011validation-rmse:0.43618\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 58 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[109]#011train-rmse:0.248491#011validation-rmse:0.435912\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 52 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[110]#011train-rmse:0.24801#011validation-rmse:0.435786\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 36 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[111]#011train-rmse:0.247489#011validation-rmse:0.435493\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 60 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[112]#011train-rmse:0.247369#011validation-rmse:0.435532\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[113]#011train-rmse:0.247413#011validation-rmse:0.435549\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 98 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[114]#011train-rmse:0.24744#011validation-rmse:0.43556\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 50 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[115]#011train-rmse:0.247225#011validation-rmse:0.435627\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 78 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[116]#011train-rmse:0.246824#011validation-rmse:0.435845\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 78 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[31m[117]#011train-rmse:0.246462#011validation-rmse:0.435775\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 62 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[31m[118]#011train-rmse:0.245592#011validation-rmse:0.435725\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 64 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[119]#011train-rmse:0.245479#011validation-rmse:0.435716\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 76 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[31m[120]#011train-rmse:0.24478#011validation-rmse:0.43562\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[121]#011train-rmse:0.244844#011validation-rmse:0.435644\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 94 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[122]#011train-rmse:0.244832#011validation-rmse:0.43564\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 52 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[31m[123]#011train-rmse:0.244118#011validation-rmse:0.435852\u001b[0m\n",
      "\u001b[31m[20:06:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 94 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[124]#011train-rmse:0.244126#011validation-rmse:0.435855\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[74]#011train-rmse:0.269897#011validation-rmse:0.434865\n",
      "\u001b[0m\n",
      "Billable seconds: 63\n"
     ]
    }
   ],
   "source": [
    "# training_job_name = 'xgboost-2019-07-02-13-50-30-261'\n",
    "estimator = sagemaker.estimator.Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_tuning_objective_metric': 'validation:rmse', 'early_stopping_rounds': '50', 'eta': '0.054923833286676146', 'gamma': '3.0417882183103795', 'max_depth': '10', 'min_child_weight': '2', 'num_round': '4000', 'objective': 'binary:logistic', 'silence': '1', 'subsample': '0.8536558502241701'}\n"
     ]
    }
   ],
   "source": [
    "print(estimator.hyperparameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # rounding and squeezing array\n",
    "    predictions = []\n",
    "    for x in test_features:\n",
    "        x = ','.join(str(val) for val in x).encode('utf-8') \n",
    "        pred = float(predictor.predict(x))\n",
    "        predictions.append(pred)\n",
    "        # print(x)\n",
    "\n",
    "    raw_preds = np.array(predictions)    \n",
    "    print(raw_preds)\n",
    "    \n",
    "    test_preds = raw_preds\n",
    "    # Normalized to range 0 to 1\n",
    "    min_pred = test_preds.min()\n",
    "    max_pred = test_preds.max()\n",
    "    print(f\"Min pred: {min_pred} Max pred: {max_pred}\")\n",
    "    test_y_preds = (test_preds - min_pred) / (max_pred - min_pred)\n",
    "    test_preds = np.round(test_y_preds)  \n",
    "    print(test_preds)\n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return tp, fp, fn, tn, precision, recall, accuracy, raw_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1.]\n",
      "[[4.100e+01 1.740e+02 8.230e+02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [9.000e+00 7.000e+01 3.960e+02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [7.700e+01 1.307e+03 8.980e+02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.400e+01 1.770e+03 1.685e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.000e+00 1.200e+01 2.300e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.800e+01 9.090e+02 1.747e+03 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "test_y = test_data.iloc[:, 0].values\n",
    "test_x = test_data.iloc[:, 1:].values\n",
    "print(test_y)\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'28.0,909.0,1747.0,1770.0,1561.0,567.0,147.0,1737.0,909.0,1937.0,1770.0,21.0,816.0,909.0,898.0,970.0,147.0,933.0,909.0,1779.0,816.0,909.0,947.0,1777.0,909.0,754.0,1805.0,1770.0,1788.0,567.0,147.0,875.0,909.0,833.0,1770.0,1520.0,1297.0,1937.0,1501.0,1805.0,1770.0,693.0,22.0,567.0,147.0,1637.0,1195.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0'\n"
     ]
    }
   ],
   "source": [
    "x = ','.join(str(val) for val in test_x[-1]).encode('utf-8')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780285716057\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pred = predictor.predict(x)\n",
    "print(float(pred))\n",
    "print(test_y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32678574 0.79644269 0.77557814 0.38392627 0.90085679 0.86234808\n",
      " 0.81323242 0.9275825  0.43325192 0.79614121 0.81789666 0.78181314\n",
      " 0.56183892 0.83131528 0.86051196 0.59374124 0.64796621 0.92559397\n",
      " 0.88101071 0.64151406 0.58214283 0.80274528 0.84412384 0.7797907\n",
      " 0.70234853 0.39340898 0.87180525 0.8669517  0.89111131 0.8191275\n",
      " 0.83048224 0.91622072 0.54515237 0.87353998 0.31071445 0.88207853\n",
      " 0.74594939 0.64250892 0.894346   0.36175376 0.60943013 0.59341592\n",
      " 0.81020766 0.9180795  0.90193707 0.63258427 0.89641726 0.6000554\n",
      " 0.78623253 0.91896486 0.66845024 0.83035636 0.92030847 0.32905725\n",
      " 0.44934645 0.24648586 0.80238605 0.64388496 0.86462373 0.83491057\n",
      " 0.50751072 0.46339455 0.6935935  0.63766003 0.88229996 0.84839934\n",
      " 0.85528398 0.87278527 0.90288305 0.353811   0.88230991 0.8473922\n",
      " 0.6591298  0.52620828 0.58381915 0.23997389 0.65244907 0.89645046\n",
      " 0.88434255 0.74354488 0.88537091 0.79744244 0.83493567 0.60971862\n",
      " 0.91204321 0.80908322 0.69283193 0.87814057 0.90142453 0.9026593\n",
      " 0.85454452 0.42611167 0.81905425 0.83961552 0.59147012 0.90232986\n",
      " 0.88415593 0.50357789 0.73170215 0.77507365 0.8933869  0.48668468\n",
      " 0.90306723 0.70693874 0.89365387 0.9058376  0.57132262 0.88600618\n",
      " 0.7911405  0.23626049 0.82975763 0.50932729 0.46441698 0.80132788\n",
      " 0.89586765 0.84917581 0.60211867 0.91707563 0.8947717  0.24123146\n",
      " 0.71100909 0.79410112 0.9000839  0.67850441 0.91648048 0.56108892\n",
      " 0.84749234 0.62927175 0.88337111 0.5905689  0.87353998 0.59689778\n",
      " 0.75882393 0.72012234 0.85455549 0.56516725 0.86928636 0.67906791\n",
      " 0.63730246 0.92049044 0.85877055 0.92400306 0.93520141 0.87326598\n",
      " 0.86920816 0.14310394 0.78028572]\n",
      "Min pred: 0.143103942275 Max pred: 0.935201406479\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1.]\n",
      "predictions  0.0  1.0\n",
      "actuals              \n",
      "0.0           19   24\n",
      "1.0            3  101\n",
      "\n",
      "Recall:     0.971\n",
      "Precision:  0.808\n",
      "Accuracy:   0.816\n",
      "\n",
      "     raw_predicted  predicted  actual\n",
      "5         0.862348        1.0     0.0\n",
      "11        0.781813        1.0     0.0\n",
      "12        0.561839        1.0     0.0\n",
      "15        0.593741        1.0     0.0\n",
      "19        0.641514        1.0     0.0\n",
      "40        0.609430        1.0     0.0\n",
      "41        0.593416        1.0     0.0\n",
      "50        0.668450        1.0     0.0\n",
      "51        0.830356        1.0     0.0\n",
      "57        0.643885        1.0     0.0\n",
      "76        0.652449        1.0     0.0\n",
      "78        0.884343        1.0     0.0\n",
      "83        0.609719        1.0     0.0\n",
      "90        0.854545        1.0     0.0\n",
      "94        0.591470        1.0     0.0\n",
      "97        0.503578        1.0     0.0\n",
      "98        0.731702        1.0     0.0\n",
      "106       0.571323        1.0     0.0\n",
      "111       0.509327        1.0     0.0\n",
      "112       0.464417        0.0     1.0\n",
      "113       0.801328        1.0     0.0\n",
      "116       0.602119        1.0     0.0\n",
      "125       0.561089        1.0     0.0\n",
      "131       0.596898        1.0     0.0\n",
      "132       0.758824        1.0     0.0\n",
      "137       0.679068        1.0     0.0\n",
      "138       0.637302        1.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Second: calculate the test accuracy\n",
    "tp, fp, fn, tn, precision, recall, accuracy, test_y_preds = evaluate(predictor, test_x, test_y)\n",
    "\n",
    "## print out the array of predicted and true labels, if you want\n",
    "results = pd.concat([pd.DataFrame(test_y_preds), pd.DataFrame(np.round(test_y_preds)), pd.DataFrame(test_y)], axis=1)\n",
    "results.columns = ['raw_predicted','predicted','actual']\n",
    "incorrect_results = results[results['predicted'] != results['actual']]\n",
    "print(incorrect_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
